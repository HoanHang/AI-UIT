{"cells": [{"cell_type": "code", "execution_count": 1, "id": "dfbd1183-b3bd-4b80-9787-884d0a55c2a0", "metadata": {"execution": {"iopub.execute_input": "2025-08-14T18:57:01.960110Z", "iopub.status.busy": "2025-08-14T18:57:01.957852Z", "iopub.status.idle": "2025-08-14T18:57:06.691111Z", "shell.execute_reply": "2025-08-14T18:57:06.688611Z"}, "executionInfo": {"elapsed": 1293, "status": "ok", "timestamp": 1711646935952, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from tqdm import tqdm\n", "from scipy import stats\n", "from scipy.spatial.distance import cosine\n", "from typing import List, Dict, Tuple"]}, {"cell_type": "code", "execution_count": 2, "id": "13c9a5ac-b2f4-4390-b07e-6ef88557bf54", "metadata": {"execution": {"iopub.execute_input": "2025-08-14T18:57:06.704504Z", "iopub.status.busy": "2025-08-14T18:57:06.702754Z", "iopub.status.idle": "2025-08-14T18:57:06.718112Z", "shell.execute_reply": "2025-08-14T18:57:06.715503Z"}, "executionInfo": {"elapsed": 7, "status": "ok", "timestamp": 1711646804012, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}}, "outputs": [], "source": ["def load_vocab_dict(path: str) -> Tuple[List[str], Dict[str, int]]:\n", "    \"\"\"\n", "    Reads a vocabulary list from a file and creates a dictionary mapping each word to its index.\n", "\n", "    Args:\n", "        path (str): The file path to the vocabulary list.\n", "\n", "    Returns:\n", "        Tuple[List[str], Dict[str, int]]: A tuple containing the list of vocabulary words and a dictionary\n", "                                          mapping each word to its index.\n", "    \"\"\"\n", "    vocab = open(path).read().strip().split('\\n')\n", "    return vocab, {word: idx for idx, word in enumerate(vocab)}"]}, {"cell_type": "code", "execution_count": 3, "id": "ad13a554-31b5-4422-89a4-8f5d2fbc2083", "metadata": {"execution": {"iopub.execute_input": "2025-08-14T18:57:06.727086Z", "iopub.status.busy": "2025-08-14T18:57:06.726209Z", "iopub.status.idle": "2025-08-14T18:57:06.737092Z", "shell.execute_reply": "2025-08-14T18:57:06.734681Z"}, "executionInfo": {"elapsed": 6, "status": "ok", "timestamp": 1711646804013, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}}, "outputs": [], "source": ["def read_corpus(path: str) -> List[str]:\n", "    \"\"\"Reads the corpus from a file, excluding the last empty entry if the file ends with a newline.\n", "\n", "    Args:\n", "        path (str): The file path to the corpus.\n", "\n", "    Returns:\n", "        List[str]: A list of strings, each representing a line from the file.\n", "    \"\"\"\n", "    return open(path).read().strip().split('\\n')"]}, {"cell_type": "code", "execution_count": 4, "id": "3dff43f3-1bd0-4ddf-84cc-da26a6f1a591", "metadata": {"execution": {"iopub.execute_input": "2025-08-14T18:57:06.747028Z", "iopub.status.busy": "2025-08-14T18:57:06.744926Z", "iopub.status.idle": "2025-08-14T18:57:06.767395Z", "shell.execute_reply": "2025-08-14T18:57:06.764995Z"}, "executionInfo": {"elapsed": 5, "status": "ok", "timestamp": 1711646804013, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}}, "outputs": [], "source": ["def counting(corpus: List[str], V: List[str], V_C: List[str], V_set: Dict[str, int], V_C_set: Dict[str, int]) -> np.ndarray:\n", "    \"\"\"\n", "    Generates a co-occurrence (counting) matrix from the given corpus, considering specified vocabularies and a window size.\n", "\n", "    Args:\n", "        corpus (List[str]): The corpus as a list of sentences.\n", "        V (List[str]): The list of vocabulary words.\n", "        V_C (List[str]): The list of context vocabulary words.\n", "        V_set (Dict[str, int]): A dictionary mapping vocabulary words to their indices.\n", "        V_C_set (Dict[str, int]): A dictionary mapping context vocabulary words to their indices.\n", "\n", "    Returns:\n", "        np.ndarray: A 2D NumPy array representing the co-occurrence matrix with dimensions (len(V), len(V_C)).\n", "    \"\"\"\n", "    # Initialize the matrix to hold word vectors\n", "    C = np.zeros((len(V), len(V_C)), dtype=float)\n", "\n", "    for line in tqdm(corpus): # Iterate over each word in the original dataset\n", "        # Append start and end tokens to the sentence\n", "        words = ['<s>'] + line.split(' ') + ['</s>']\n", "        length = len(words)\n", "\n", "        for idx, word in enumerate(words): # Iterate over each word in the current sentence\n", "            # Skip '<s>' and '</s>', as they are not real words\n", "            if idx > 0 and idx < length - 1 and word in V_set:\n", "                ### BEGIN SOLUTION\n", "                # Get current word index\n", "                word_idx = V_set[word]\n", "\n", "                # Define window size (you can adjust this)\n", "                window_size = 5\n", "\n", "                # Get context words within window\n", "                start = max(1, idx - window_size)\n", "                end = min(length - 1, idx + window_size + 1)\n", "\n", "                for context_pos in range(start, end):\n", "                    if context_pos != idx:  # Skip the current word itself\n", "                        context_word = words[context_pos]\n", "                        if context_word in V_C_set:\n", "                            context_idx = V_C_set[context_word]\n", "                            # Update co-occurrence count\n", "                            C[word_idx][context_idx] += 1.0 / (abs(context_pos - idx))  # Weight by distance\n", "                ### END SOLUTION\n", "    return C"]}, {"cell_type": "code", "execution_count": 5, "id": "40f3a099-3a9d-4fd6-98f3-4bd02ad60888", "metadata": {"execution": {"iopub.execute_input": "2025-08-14T18:57:06.776318Z", "iopub.status.busy": "2025-08-14T18:57:06.774730Z", "iopub.status.idle": "2025-08-14T18:57:06.791933Z", "shell.execute_reply": "2025-08-14T18:57:06.789442Z"}, "executionInfo": {"elapsed": 500, "status": "ok", "timestamp": 1711646943804, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}}, "outputs": [], "source": ["def eval_word_similarity(C: np.ndarray, V_set: Dict[str, int], path: str) -> float:\n", "    pairs = []\n", "    with open(path, encoding='utf-8') as f:\n", "        for line in f.readlines()[1:]:\n", "            parts = line.strip().split('\\t')\n", "            if len(parts) != 3:\n", "                continue\n", "            w1, w2, score_str = parts\n", "            if w1 in V_set and w2 in V_set:\n", "                score = float(score_str)\n", "                v1, v2 = C[V_set[w1]], C[V_set[w2]]\n", "                sim = 1 - cosine(v1, v2) if np.linalg.norm(v1) > 0 and np.linalg.norm(v2) > 0 else 0.0\n", "                pairs.append((sim, score))\n", "\n", "    if not pairs:\n", "        return 0.0\n", "\n", "    x, y = zip(*pairs)\n", "    corr = stats.spearmanr(x, y).correlation\n", "    return float(corr) if not np.isnan(corr) else 0.0"]}, {"cell_type": "code", "execution_count": 6, "id": "662f6186-e198-46a6-aa94-500ee45f4b0f", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2025-08-14T18:57:06.800250Z", "iopub.status.busy": "2025-08-14T18:57:06.799365Z", "iopub.status.idle": "2025-08-14T19:02:13.171807Z", "shell.execute_reply": "2025-08-14T19:02:13.169085Z"}, "executionInfo": {"elapsed": 114004, "status": "ok", "timestamp": 1711646918013, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}, "outputId": "cbca5f46-8a0f-4da5-9a89-51835eb1dcf8"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 997898/997898 [05:00<00:00, 3322.09it/s]\n"]}], "source": ["# Read the main vocabulary and its indices from a file,\n", "# creating a list of words (V) and a dictionary mapping words to indices (V_set).\n", "V, V_set = load_vocab_dict('./data/main_words.txt')\n", "\n", "# Read the context vocabulary and its indices from a separate file,\n", "# creating a list of context words (V_C) and a dictionary mapping these words to indices (V_C_set).\n", "V_C, V_C_set = load_vocab_dict('./data/context_words.txt')\n", "\n", "# Read the corpus from a text file, creating a list where each item represents a document or line in the corpus.\n", "corpus = read_corpus('./data/corpus.txt')\n", "\n", "# Generate a co-occurrence (counting) matrix from the corpus using the main and context vocabularies.\n", "C = counting(corpus, V, V_C, V_set, V_C_set)"]}, {"cell_type": "code", "execution_count": 7, "id": "68e8c860-49a8-45b5-bd5e-634f59d1b29a", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2025-08-14T19:02:13.181036Z", "iopub.status.busy": "2025-08-14T19:02:13.180343Z", "iopub.status.idle": "2025-08-14T19:02:13.444530Z", "shell.execute_reply": "2025-08-14T19:02:13.441702Z"}, "executionInfo": {"elapsed": 509, "status": "ok", "timestamp": 1711646948109, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}, "outputId": "24707dd3-b3ed-472d-8b03-52fee9edd664"}, "outputs": [{"data": {"text/plain": ["0.23035753802145398"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["### BEGIN PUBLIC TESTS\n", "eval_word_similarity(C, V_set, './data/men.txt')\n", "### BEGIN PUBLIC TESTS"]}, {"cell_type": "code", "execution_count": 8, "id": "4e461233-07a3-4187-90ce-c07535f23f2d", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2025-08-14T19:02:13.453307Z", "iopub.status.busy": "2025-08-14T19:02:13.452599Z", "iopub.status.idle": "2025-08-14T19:02:13.551627Z", "shell.execute_reply": "2025-08-14T19:02:13.549182Z"}, "executionInfo": {"elapsed": 328, "status": "ok", "timestamp": 1711646949884, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}, "outputId": "f8b94b4c-a48d-4102-9f79-9d398fe9a9bf"}, "outputs": [{"data": {"text/plain": ["0.058947013073989286"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["### BEGIN PUBLIC TESTS\n", "eval_word_similarity(C, V_set, './data/simlex-999.txt')\n", "### BEGIN PUBLIC TESTS"]}, {"cell_type": "code", "execution_count": 9, "id": "0b48b352-2b7b-4026-8117-7e2cdcf9ea1b", "metadata": {"execution": {"iopub.execute_input": "2025-08-14T19:02:13.561850Z", "iopub.status.busy": "2025-08-14T19:02:13.561120Z", "iopub.status.idle": "2025-08-14T19:02:13.579973Z", "shell.execute_reply": "2025-08-14T19:02:13.577670Z"}, "executionInfo": {"elapsed": 22862, "status": "ok", "timestamp": 1711646974553, "user": {"displayName": "Nguyễn Đức Vũ", "userId": "07288779277842550568"}, "user_tz": -420}}, "outputs": [], "source": ["def improve_C(C: np.ndarray, corpus: List[str], V_C: List[str], V_C_set: Dict[str, int]) -> np.ndarray:\n", "    ### BEGIN SOLUTION\n", "    # Apply Positive Pointwise Mutual Information (PPMI)\n", "        # Calculate probabilities\n", "        total = np.sum(C)\n", "        word_probs = np.sum(C, axis=1) / total\n", "        context_probs = np.sum(C, axis=0) / total\n", "\n", "        # Calculate PMI\n", "        C_improved = np.zeros_like(C)\n", "        for i in range(C.shape[0]):\n", "            for j in range(C.shape[1]):\n", "                if C[i,j] > 0:\n", "                    pmi = np.log2((C[i,j] / total) / (word_probs[i] * context_probs[j]))\n", "                    C_improved[i,j] = max(0, pmi)  # PPMI\n", "                else:\n", "                    C_improved[i,j] = 0\n", "\n", "        # Apply SVD for dimensionality reduction\n", "        U, s, Vh = np.linalg.svd(C_improved, full_matrices=False)\n", "        k = 100  # Reduced dimension\n", "        C_reduced = U[:, :k] @ np.diag(s[:k])\n", "\n", "        # Normalize rows (optional but often helpful)\n", "        norms = np.linalg.norm(C_reduced, axis=1, keepdims=True)\n", "        norms[norms == 0] = 1  # Avoid division by zero\n", "        C_normalized = C_reduced / norms\n", "\n", "        return C_normalized\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "    ### END SOLUTION"]}, {"cell_type": "markdown", "id": "37e06a79-2f20-4ead-8f2d-d90063989f0b", "metadata": {}, "source": ["### <span style=\"color:red; font-size:small;\">Part #1: {\"men\": 0.5388839800291707, \"simlex-999\": 0.2346222684809021}</span>\n"]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 5}